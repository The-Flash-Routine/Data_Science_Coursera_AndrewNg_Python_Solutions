{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for importing svm module from scikit learn\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading .mat extension files to program\n",
    "import scipy.io as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading regular expression library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dealing with files like renaming, deleting etc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for word stemming purpose\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this converts all characters in a file to lowercase by taking location of file as input argument\n",
    "def processemail(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    for line in old:\n",
    "        for char in line:\n",
    "            new.write(char.lower())\n",
    "    \n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this replaces all the numbers in a file with the word \"number\" by taking location of file as input argument\n",
    "def repnumbynum(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",'w')\n",
    "    old=open(dfl,'r')\n",
    "    for line in old:\n",
    "        yo=re.sub(r'\\d+',\"number \",line)\n",
    "        new.write(yo)\n",
    "        \n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this replaces all the $ signs in a file with the word \"dollar\" by taking location of file as input argument\n",
    "def repdolbydol(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",'w')\n",
    "    old=open(dfl,'r')\n",
    "    for line in old:\n",
    "        for char in line:\n",
    "          if char=='$':\n",
    "                new.write(\"dollar\")\n",
    "          else:\n",
    "                new.write(char)\n",
    "            \n",
    "        \n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this removes all the html tags from the file\n",
    "def remhtmltags(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    for line in old:\n",
    "        heyu=re.sub(r'<.*?>',\"\",line)\n",
    "        new.write(heyu)\n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this replaces all the URL's in a file with the word \"httpaddr\" by taking location of file as input argument\n",
    "def normurls(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    for line in old:\n",
    "        venom=re.sub(r'http://[\\w/.]+',r'httpaddr',line)\n",
    "        new.write(venom)\n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this replaces all the email addresses in a file with the word \"emailaddr\" by taking location of file as input argument\n",
    "def normemail(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    for line in old:\n",
    "        venom=re.sub(r'[.\\w_-]+@[.\\w_-]+',r'emailaddr',line)\n",
    "        new.write(venom)\n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this performs steeming operation on each word of file\n",
    "def stembo(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    ps=PorterStemmer()\n",
    "    for line in old:\n",
    "        heyu=re.findall(r'\\w+',line)\n",
    "        spydy=[]\n",
    "        for word in heyu:\n",
    "            spydy.append(ps.stem(word))\n",
    "        heyu=' '.join(spydy)\n",
    "        new.write(heyu)\n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is removes all punctuations and white spaces and replace them with a single space\n",
    "def trimwhitespacesandpunc(dfl):\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    old=open(dfl,\"r\")\n",
    "    oldread=old.read()\n",
    "    heya=re.sub(r'[\\t\\n.,:;!#%&?\\'-]+',r' ',oldread)\n",
    "    new.write(heya)\n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is basically a compiler function which executes all processing functions(listed above) to the file\n",
    "#taking location of file to process and location of vocablury file as input\n",
    "#this returns a feature vector x by taking above listed arguments\n",
    "#basically it converst a file to a feature vector\n",
    "def all_processing(vocabloc,dfl):\n",
    "    processemail(dfl)\n",
    "    repnumbynum(dfl)\n",
    "    repdolbydol(dfl)\n",
    "    remhtmltags(dfl)#\n",
    "    normurls(dfl)\n",
    "    normemail(dfl)\n",
    "    trimwhitespacesandpunc(dfl)\n",
    "    stembo(dfl)\n",
    "    mapvocab(vocabloc,dfl)\n",
    "    x=generatefeaturevec(dfl)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes preprocessed file and converst to feature vector\n",
    "def generatefeaturevec(dfl):\n",
    "    old=open(dfl,\"r\")\n",
    "    oldread=old.read()\n",
    "    x=np.zeros(1899)\n",
    "    hey=re.findall(r'\\w+',oldread)\n",
    "    for i in hey:\n",
    "        num=int(i)\n",
    "        x[num-1]=1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this maps vocab word positions to the desired file\n",
    "def mapvocab(vocabloc,dfl):\n",
    "    vocab=pd.read_csv(vocabloc,header=None,sep='\\t',names=[\"index\",\"word\"])\n",
    "    filename=re.search(r'/\\w+.txt',dfl)\n",
    "    hey=filename.group()\n",
    "    hey=hey[1:]\n",
    "    old=open(dfl,\"r\")\n",
    "    oldread=old.read()\n",
    "    new=open(\"temp.txt\",\"w\")\n",
    "    venom=re.findall(r'\\w+',oldread)\n",
    "    for x in venom:\n",
    "      loc=-1\n",
    "      for i in range(0,1899):\n",
    "        if x==vocab.iloc[i,1]:\n",
    "          loc=i+1\n",
    "          break\n",
    "      if loc!=-1:\n",
    "        new.write(str(loc))\n",
    "        new.write(' ')\n",
    "    \n",
    "    new.close()\n",
    "    old.close()\n",
    "    os.remove(hey)\n",
    "    os.rename(\"temp.txt\",hey)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this analyzes the accuracy of trained classifier\n",
    "def classifieraccuracy(clf,x,y):\n",
    "    [m,n]=x.shape\n",
    "    right=0\n",
    "    for i in range(0,m):\n",
    "        if clf.predict([x[i,:]])==y[i]:\n",
    "            right=right+1\n",
    "    acc=(right/m)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of vocablury file\n",
    "vocabloc=\"C:/Users/RitKat/Desktop/Projects_Flash/Done using Python_Andrew_Ng_Coursera/Week 7/machine-learning-ex6/ex6/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of sample email file named \"hehe.txt\"\n",
    "#basicallly this file i had created with exact contents of file \"emailSample1.txt\"\n",
    "#this hehe.txt file was used in development of program so original files can be kept secure\n",
    "\n",
    "datafileloc10=\"C:/Users/RitKat/Desktop/Projects_Flash/Done using Python_Andrew_Ng_Coursera/Week 7/machine-learning-ex6/ex6/hehe.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature vector obtained from this hehe.txt file or can say from emailSample1.txt file\n",
    "X_self=all_processing(vocabloc,datafileloc10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#showing this feature vector has 45 ones\n",
    "#this 45 number can from the fact that in problem statement pdf it was written that this x if done everything properly\n",
    "#will contain 45 elements valued 1 and rest zero\n",
    "print(np.sum(X_self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of data set file_1\n",
    "traineddatafileloc=\"C:/Users/RitKat/Desktop/Projects_Flash/Done using Python_Andrew_Ng_Coursera/Week 7/machine-learning-ex6/ex6/spamTrain.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training preprocessed data set\n",
    "data=sci.loadmat(traineddatafileloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#identifying datatype of this data object\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__\n",
      "__version__\n",
      "__globals__\n",
      "X\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "#knowing keys present in this data file\n",
    "for i in data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting inout and ouput training examples set from data\n",
    "x=np.array(data[\"X\"])\n",
    "y=np.array(data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training classifier with linear kernel with C value to be 0.1\n",
    "#this C=0.1 was mentioned in problem statement pdf\n",
    "clf=svm.SVC(kernel='linear',C=0.1)\n",
    "clf.fit(x,y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.825\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy on training set\n",
    "print(classifieraccuracy(clf,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of datatest file\n",
    "testdatafileloc=\"C:/Users/RitKat/Desktop/Projects_Flash/Done using Python_Andrew_Ng_Coursera/Week 7/machine-learning-ex6/ex6/spamTest.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest=sci.loadmat(testdatafileloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__\n",
      "__version__\n",
      "__globals__\n",
      "Xtest\n",
      "ytest\n"
     ]
    }
   ],
   "source": [
    "#knowing keys present in this datatest dictionary object\n",
    "for i in datatest:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting inout and ouput training examples set from datatest\n",
    "xtest=np.array(datatest[\"Xtest\"])\n",
    "ytest=np.array(datatest[\"ytest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy on test set\n",
    "print(classifieraccuracy(clf,xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
